import os
from dotenv import load_dotenv
import pandas as pd
from sqlalchemy import create_engine, text

import openai
from openai import RateLimitError
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from langchain_community.utilities import SQLDatabase
from langchain_experimental.sql import SQLDatabaseChain
from langchain_openai import ChatOpenAI

# 1) Load and set your OpenAI key
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# 2) Prepare SQLite and load your CSV
DB_PATH = "data/df_total.db"
engine = create_engine(f"sqlite:///{DB_PATH}", echo=False)
df = pd.read_csv("data/df_total.csv")
df.to_sql("df_total", con=engine, if_exists="replace", index=False)

# 3) Wrap the DB in LangChain’s utility
db = SQLDatabase.from_uri(f"sqlite:///{DB_PATH}")

# 4) Initialize two ChatOpenAI LLMs: a “premium” and a “fallback”
llm_primary = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
    api_key=os.getenv("OPENAI_API_KEY"),
)
llm_fallback = ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0,
    api_key=os.getenv("OPENAI_API_KEY"),
)

# 5) Create two SQLDatabaseChains
chain_primary = SQLDatabaseChain.from_llm(llm_primary, db, verbose=True)
chain_fallback = SQLDatabaseChain.from_llm(llm_fallback, db, verbose=False)

# 6) A helper that retries on OpenAI rate‐limit errors
@retry(
    retry=retry_if_exception_type(RateLimitError),
    wait=wait_exponential(multiplier=1, max=4),
    stop=stop_after_attempt(3),
)
def invoke_chain(chain: SQLDatabaseChain, query: str) -> str:
    ai_msg = chain.invoke(query)
    return ai_msg.content.strip()

def handle_query(user_query: str) -> str:
    q_lower = user_query.lower()

    # Shortcut for simple row‐count questions
    if any(kw in q_lower for kw in ("how many rows", "row count", "number of rows")):
        try:
            with engine.connect() as conn:
                count = conn.execute(text("SELECT COUNT(*) FROM df_total")).scalar()
            return f"There are {count} rows in the dataset."
        except Exception as e:
            return f"❌ Error counting rows: {e}"

    # Otherwise, try the primary chain, falling back on rate‐limit
    try:
        return invoke_chain(chain_primary, user_query)
    except RateLimitError:
        try:
            return invoke_chain(chain_fallback, user_query)
        except RateLimitError:
            return (
                "⚠️ OpenAI rate‐limits reached on both models. "
                "Please check your API quota or billing and try again later."
            )
    except Exception as e:
        return f"❌ An unexpected error occurred: {e}"
